# Recent Advances in Vision Pre-training

If you want to contribute this repository, please fork and revise, and create a pull request for a update. Alternatively, you can contact Xiaoshui Huang[huangxiaoshui@pjlab.org.cn] to do the update. 

## Table of Contents

* [Leaning paradigm](#leaning-paradigm)
* [Model design](#model-design)
* [Fine tune](#Fine-tune)

 
# Leaning paradigm

2022

[Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality](https://arxiv.org/abs/2205.10063) CVPR2022,[**]

[Multi-modal Alignment using Representation Codebook](https://arxiv.org/abs/2203.00048) CVPR2022, [**]

[In Defense of Image Pre-Training for Spatiotemporal Recognition](https://arxiv.org/abs/2205.01721) arXiv 2022, [**]

[Omnivore: A Single Model for Many Visual Modalities](https://arxiv.org/abs/2201.08377) CVPR 2022, [**]

[SimMIM: A Simple Framework for Masked Image Modeling](https://arxiv.org/abs/2111.09886) CVPR 2022, [**]

[Versatile Multi-Modal Pre-Training for Human-Centric Perception](https://arxiv.org/pdf/2203.13815.pdf) CVPR 2022, [***]

[CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding](https://arxiv.org/pdf/2203.00680.pdf) CVPR 2022, [**]

[PointCLIP: Point Cloud Understanding by CLIP](https://arxiv.org/abs/2112.02413) CVPR 2022, [**]

[PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision](https://arxiv.org/pdf/2203.15625.pdf) CVPR 2022, [**]

[Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling](https://arxiv.org/abs/2111.14819) CVPR 2022, [**]

[Masked Discrimination for Self-Supervised Learning on Point Clouds](https://arxiv.org/pdf/2203.11183.pdf) arXiv 2022, [**]

[Masked Autoencoders for Point Cloud Self-supervised Learning](https://arxiv.org/pdf/2203.06604.pdf) arXiv 2022, [*]

[Implicit Autoencoder for Point Cloud Self-supervised Representation Learning](https://arxiv.org/abs/2201.00785) arXiv 2022, [**]

[RotoGrad: Gradient Homogenization in Multitask Learning](https://arxiv.org/pdf/2103.02631.pdf) ICLR 2022, [**]

[X-Learner: Learning Cross Sources and Tasks for Universal Visual Representation](https://arxiv.org/pdf/2203.08764.pdf) arXiv 2022, [**]

[A Unified Query-based Paradigm for Point Cloud Understanding](https://arxiv.org/pdf/2203.01252.pdf) arXiv 2022, [**]

[GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/pdf/2202.11094.pdf) CVPR 2022, [**]

2021

[Unsupervised Point Cloud Pre-Training via Occlusion Completion](https://arxiv.org/abs/2010.01089) ICCV 2021, [**]

[Contrastive Multimodal Fusion with TupleInfoNCE](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Contrastive_Multimodal_Fusion_With_TupleInfoNCE_ICCV_2021_paper.pdf) ICCV 2021, [**]

[Pri3D: Can 3D Priors Help 2D Representation Learning?](https://arxiv.org/pdf/2104.11225.pdf) ICCV 2021, [**]

[Learning Transferable Features for Point Cloud Detection via 3D Contrastive Co-training](https://proceedings.neurips.cc/paper/2021/file/b3b25a26a0828ea5d48d8f8aa0d6f9af-Paper.pdf) NeurIPS 2021, [*]

 
2020

[P4Contrast: Contrastive Learning with Pairs of Point-Pixel Pairs for RGB-D Scene Understanding](https://arxiv.org/pdf/2012.13089.pdf) arXiv 2020, [*]

[PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding](https://arxiv.org/abs/2007.10985) ECCV 2020, [**]


2019

[Self-Supervised Deep Learning on Point Clouds by Reconstructing Space](https://arxiv.org/abs/1901.08396) NuerIPS 2019, [**]

2018

[Representation Learning with Contrastive Predictive Coding](https://arxiv.org/pdf/1807.03748.pdf) NeurIPS 2018, [***]

[Learning Representations and Generative Models for 3D Point Clouds](https://arxiv.org/pdf/1707.02392.pdf)  ICML 2018, [*]



# Model design

2022

[Inception Transformer](https://arxiv.org/abs/2205.12956) arXiv 2022, [**]

[Compositional Attention: Disentangling Search and Retrieval](https://openreview.net/forum?id=IwJPj2MBcIa) ICLR 2022, [**]

[Brain-inspired Multilayer Perceptron with Spiking Neurons](https://arxiv.org/pdf/2203.14679.pdf) arXiv 2022, [**]

[Efficient Language Modeling with Sparse all-MLP](https://arxiv.org/abs/2203.06850) arXiv 2022, [**]

[Neighborhood Attention Transformer](https://arxiv.org/pdf/2204.07143.pdf)arXiv 2022, [***]

[Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework](https://arxiv.org/abs/2202.07123) ICLR 2022, [*]

[On Efficient Transformer-Based Image Pre-training for Low-Level Vision](https://arxiv.org/abs/2112.10175) arxiv 2022, [**]

[Learning Patch-to-Cluster Attention in Vision Transformer](https://arxiv.org/pdf/2203.11987.pdf) arXiv 2022, [**]

[BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/abs/2201.12086) 

[An Image Patch is a Wave: Phase-Aware Vision MLP](https://arxiv.org/pdf/2111.12294.pdf)  CVPR 2022, [**]

[How Do Vision Transformers Work?](https://arxiv.org/abs/2202.06709) ICLR 2022, [***]

[Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/abs/2111.09883) CVPR 2022, [**]

[MetaFormer is Actually What You Need for Vision](https://arxiv.org/pdf/2111.11418.pdf) CVPR 2022, [**]

[UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation](https://arxiv.org/abs/2204.00631) arXiv 2022, [**]

[MaxViT: Multi-Axis Vision Transformer](https://arxiv.org/pdf/2204.01697.pdf) arXiv 2022, [**]

[3D Shuffle-Mixer: An Efficient Context-Aware Vision Learner of Transformer-MLP Paradigm for Dense Prediction in Medical Volume](https://arxiv.org/abs/2204.06779) arXiv 2022, [*]


2021

[Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) ICCV 2021, [***]

[MLP-Mixer: An all-MLP Architecture for Vision](https://proceedings.neurips.cc//paper/2021/file/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Paper.pdf) NeurIPS 2021, [***]

[CoAtNet: Marrying Convolution and Attention for All Data Sizes](https://arxiv.org/abs/2106.04803) NeurIPS 2021, [***]


# Fine tune

2022

[Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution](https://openreview.net/forum?id=UYneFzXSJWh) ICLR 2022, [**]

[P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/abs/2110.07602) ACL 2022, [**]

[PPT: Pre-trained Prompt Tuning for Few-shot Learning](https://arxiv.org/pdf/2109.04332.pdf) ACL 2022, [***]

[Conditional Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2203.05557) CVPR 2022, [**]

[Visual Prompt Tuning](https://arxiv.org/pdf/2203.12119.pdf) arXiv 2022, [**]

2021

[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/abs/2101.00190) ACL 2021, [**]

[Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/abs/2107.13586) arXiv 2021, [**]

[The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/abs/2104.08691) EMNLP 2021, [***]